{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75cfaa73-2e94-48dc-abbd-476e267b61a6",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'transformers'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pipeline\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlogging\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'transformers'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import pipeline\n",
    "import logging\n",
    "import os\n",
    "\n",
    "# Set up logging configuration\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Set the desired working directory \n",
    "desired_directory = '/Users/henrychang/sys_two_ai' \n",
    "os.chdir(desired_directory) \n",
    "# Verify the change \n",
    "current_directory = os.getcwd() \n",
    "print(\"Current Working Directory:\", current_directory)\n",
    "\n",
    "class CybersecurityDetector:\n",
    "    def __init__(self, input_file, output_file):\n",
    "        \"\"\"\n",
    "        Initializes the CybersecurityDetector with input and output file paths.\n",
    "\n",
    "        Parameters:\n",
    "            input_file (str): Path to the input CSV file.\n",
    "            output_file (str): Path to save the output CSV file.\n",
    "        \"\"\"\n",
    "        self.input_file = input_file\n",
    "        self.output_file = output_file\n",
    "        self.df = pd.DataFrame()\n",
    "        try:\n",
    "            # Initialize the threat detection model\n",
    "            self.threat_detection_model = pipeline(\"text-generation\", model=\"gpt-4\")\n",
    "            logger.info(\"Threat detection model initialized\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error initializing threat detection model: {e}\")\n",
    "\n",
    "    def load_data(self):\n",
    "        \"\"\"\n",
    "        Loads data from the specified CSV file into a DataFrame (self.df).\n",
    "        \"\"\"\n",
    "        try:\n",
    "            self.df = pd.read_csv(self.input_file)\n",
    "            logger.info(\"Data loaded\")\n",
    "        except FileNotFoundError:\n",
    "            logger.error(f\"Error: File {self.input_file} not found.\")\n",
    "        except pd.errors.EmptyDataError:\n",
    "            logger.error(\"Error: No data in the file.\")\n",
    "        except pd.errors.ParserError:\n",
    "            logger.error(\"Error: Parsing error.\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error during data loading: {e}\")\n",
    "\n",
    "    def preprocess_data(self):\n",
    "        \"\"\"\n",
    "        Fills missing values in numeric, categorical, datetime, and boolean columns with appropriate replacements.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            for col in self.df.columns:\n",
    "                if self.df[col].dtype in ['float64', 'int64']:  # Numeric columns\n",
    "                    self.df[col].fillna(self.df[col].mean(), inplace=True)  # Replace with mean (or use median, 0, etc.)\n",
    "                elif self.df[col].dtype == 'object':  # Categorical columns\n",
    "                    self.df[col].fillna(self.df[col].mode()[0], inplace=True)  # Replace with mode (most frequent value)\n",
    "                elif pd.api.types.is_datetime64_any_dtype(self.df[col]):  # Datetime columns\n",
    "                    self.df[col].fillna(self.df[col].min(), inplace=True)  # Replace with earliest date (or a default date)\n",
    "                elif self.df[col].dtype == 'bool':  # Boolean columns\n",
    "                    self.df[col].fillna(False, inplace=True)  # Replace with False (or True, or majority value)\n",
    "            logger.info(\"Data preprocessed\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error during preprocessing: {e}\")\n",
    "\n",
    "    def simple_filter(self):\n",
    "        \"\"\"\n",
    "        Applies a simple rule-based filter to remove non-threat rows based on certain conditions.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Define conditions to filter out non-threat rows\n",
    "            filter_conditions = ['login successful', 'system update']\n",
    "            self.df = self.df[~self.df['text'].str.contains('|'.join(filter_conditions), case=False)]\n",
    "            logger.info(\"Simple filtering applied\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error during simple filtering: {e}\")\n",
    "\n",
    "    def filter_anomalies(self):\n",
    "        \"\"\"\n",
    "        Filters data to include only anomalies based on the anomaly_score column.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            self.df = self.df[self.df['anomaly_score'] < 0.5]\n",
    "            logger.info(\"Filtered to anomalies only\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error during anomaly filtering: {e}\")\n",
    "\n",
    "    def detect_threats(self):\n",
    "        \"\"\"\n",
    "        Detects threats using a generative AI model by analyzing log entries and their classifications.\n",
    "        \"\"\"\n",
    "        def detect_threat(row):\n",
    "            try:\n",
    "                # Create a prompt for threat detection\n",
    "                prompt = f\"Log entry: {row['text']}\\nClassification: {row['classification']}\\nPredictive Anomaly Label: {row['anomaly_label']}\\nIs this a threat?\"\n",
    "                generated_text = self.threat_detection_model(prompt, max_length=50, num_return_sequences=1)[0]['generated_text']\n",
    "                return 'Threat' if 'threat' in generated_text.lower() else 'Normal'\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error during threat detection for row: {row.name} - {e}\")\n",
    "                return 'Error'\n",
    "       \n",
    "        try:\n",
    "            self.df['threat_detection'] = self.df.apply(detect_threat, axis=1)\n",
    "            logger.info(\"Threats detected using generative AI\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error applying threat detection: {e}\")\n",
    "\n",
    "    def save_data(self):\n",
    "        \"\"\"\n",
    "        Saves the DataFrame with threat detection results to the specified output CSV file.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            self.df.to_csv(self.output_file, index=False)\n",
    "            logger.info(f\"Results saved to {self.output_file}\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error saving data: {e}\")\n",
    "\n",
    "    def run(self):\n",
    "        \"\"\"\n",
    "        Orchestrates the entire workflow by calling the methods in sequence.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            self.load_data()\n",
    "            self.preprocess_data()\n",
    "            self.simple_filter()\n",
    "            self.filter_anomalies()\n",
    "            self.detect_threats()\n",
    "            self.save_data()\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error in run process: {e}\")\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    input_data_dir = current_directory + '/input/'\n",
    "    output_data_dir = current_directory + '/output/'\n",
    "    \n",
    "    detector = CybersecurityDetector(input_data_dir + '/enriched_data.csv', \n",
    "                                     output_data_dir + '/detection_results.csv')\n",
    "    detector.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9abc97eb-939d-46cf-9da9-ee8039fd0859",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
