{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "83ff8c74-1569-4b54-b9fd-10e33e6d82a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-30 16:28:31,556 - INFO - Data loaded\n",
      "/var/folders/4r/wd267p9523z8jvdn8464p4wh0000gn/T/ipykernel_18038/3241992964.py:67: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  self.df[col].fillna(self.df[col].mean(), inplace=True)  # Replace with mean (or use median, 0, etc.)\n",
      "/var/folders/4r/wd267p9523z8jvdn8464p4wh0000gn/T/ipykernel_18038/3241992964.py:69: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  self.df[col].fillna(self.df[col].mode()[0], inplace=True)  # Replace with mode (most frequent value)\n",
      "2024-12-30 16:28:31,558 - INFO - Data preprocessed\n",
      "2024-12-30 16:28:31,621 - INFO - Isolation Forest model trained.\n",
      "2024-12-30 16:28:31,625 - INFO - Model accuracy on test data: 0.0\n",
      "2024-12-30 16:28:31,626 - INFO - Confusion Matrix:\n",
      "2024-12-30 16:28:31,626 - INFO - [[0 2]\n",
      " [0 0]]\n",
      "/Users/henrychang/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/henrychang/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/henrychang/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/henrychang/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/henrychang/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/henrychang/Library/Python/3.9/lib/python/site-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "2024-12-30 16:28:31,629 - INFO - Classification Report:\n",
      "2024-12-30 16:28:31,629 - INFO -               precision    recall  f1-score   support\n",
      "\n",
      "        -1.0       0.00      0.00      0.00       2.0\n",
      "         1.0       0.00      0.00      0.00       0.0\n",
      "\n",
      "    accuracy                           0.00       2.0\n",
      "   macro avg       0.00      0.00      0.00       2.0\n",
      "weighted avg       0.00      0.00      0.00       2.0\n",
      "\n",
      "2024-12-30 16:28:31,630 - INFO - Vectorizer saved\n",
      "2024-12-30 16:28:31,649 - INFO - Isolation Forest model saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Working Directory: /Users/henrychang/sys_two_ai\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "The following code is an ML-based classifier. It generates anomaly-related features that can \n",
    "filter out non-threat-related events. Additionally, it can be used for data transformation \n",
    "during inference, whether in stream-based mode or batch processing mode.\n",
    "'''\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "import joblib\n",
    "import logging\n",
    "import os # Get the current working directory \n",
    "\n",
    "# Set the desired working directory \n",
    "desired_directory = '/Users/henrychang/sys_two_ai' \n",
    "os.chdir(desired_directory) \n",
    "# Verify the change \n",
    "current_directory = os.getcwd() \n",
    "print(\"Current Working Directory:\", current_directory)\n",
    "\n",
    "# Set up logging configuration\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "class AnomalyClassifier:\n",
    "    def __init__(self, input_file, vectorizer_file, trained_model):\n",
    "        \"\"\"\n",
    "        Initializes the AnomalyClassifier with the input file, vectorizer file, and trained model.\n",
    "\n",
    "        Parameters:\n",
    "            input_file (str): Path to the input CSV file.\n",
    "            vectorizer_file (str): Path to save the trained CountVectorizer.\n",
    "            trained_model (str): Path to save the trained Isolation Forest model.\n",
    "        \"\"\"\n",
    "        self.input_file = input_file\n",
    "        self.vectorizer_file = vectorizer_file\n",
    "        self.trained_model = trained_model\n",
    "        self.df = pd.DataFrame()\n",
    "        self.vectorizer = CountVectorizer()\n",
    "        self.isolation_forest = IsolationForest(n_estimators=100, contamination=0.1)\n",
    "\n",
    "    def load_data(self):\n",
    "        \"\"\"\n",
    "        Loads data from the specified CSV file into a DataFrame (self.df).\n",
    "        \"\"\"\n",
    "        try:\n",
    "            self.df = pd.read_csv(self.input_file)\n",
    "            logger.info(\"Data loaded\")\n",
    "        except FileNotFoundError:\n",
    "            logger.error(f\"Error: File {self.input_file} not found.\")\n",
    "        except pd.errors.EmptyDataError:\n",
    "            logger.error(\"Error: No data in the file.\")\n",
    "        except pd.errors.ParserError:\n",
    "            logger.error(\"Error: Parsing error.\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error during data loading: {e}\")\n",
    "\n",
    "    def preprocess_data(self):\n",
    "        \"\"\"\n",
    "        Fills missing values in numeric, categorical, datetime, and boolean columns with appropriate replacements.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            for col in self.df.columns:\n",
    "                if self.df[col].dtype in ['float64', 'int64']:  # Numeric columns\n",
    "                    self.df[col].fillna(self.df[col].mean(), inplace=True)  # Replace with mean (or use median, 0, etc.)\n",
    "                elif self.df[col].dtype == 'object':  # Categorical columns\n",
    "                    self.df[col].fillna(self.df[col].mode()[0], inplace=True)  # Replace with mode (most frequent value)\n",
    "                elif pd.api.types.is_datetime64_any_dtype(self.df[col]):  # Datetime columns\n",
    "                    self.df[col].fillna(self.df[col].min(), inplace=True)  # Replace with earliest date (or a default date)\n",
    "                elif self.df[col].dtype == 'bool':  # Boolean columns\n",
    "                    self.df[col].fillna(False, inplace=True)  # Replace with False (or True, or majority value)\n",
    "            logger.info(\"Data preprocessed\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error during preprocessing: {e}\")\n",
    "\n",
    "    def vectorize_data(self):\n",
    "        \"\"\"\n",
    "        Vectorizes text data for anomaly detection and splits it into training and testing sets.\n",
    "\n",
    "        Returns:\n",
    "            tuple: Vectorized training data, vectorized testing data, training index, testing index.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Vectorize text data for anomaly detection\n",
    "            text_data = self.df['log_text']\n",
    "\n",
    "            # Split data into training and testing sets\n",
    "            X_train, X_test = train_test_split(text_data, test_size=0.2, random_state=42)\n",
    "\n",
    "            # Fit and transform the vectorizer on training data, transform testing data\n",
    "            vectorized_train = self.vectorizer.fit_transform(X_train)\n",
    "            vectorized_test = self.vectorizer.transform(X_test)\n",
    "\n",
    "            return vectorized_train, vectorized_test, X_train.index, X_test.index\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error during vectorization: {e}\")\n",
    "\n",
    "    def train_isolation_forest(self, vectorized_train, vectorized_test, train_index, test_index):\n",
    "        \"\"\"\n",
    "        Trains the Isolation Forest model on the vectorized training data.\n",
    "        Predicts anomalies on the testing data and adds predictions to the DataFrame.\n",
    "        Evaluates model accuracy on test data.\n",
    "\n",
    "        Parameters:\n",
    "            vectorized_train (sparse matrix): Vectorized training data.\n",
    "            vectorized_test (sparse matrix): Vectorized testing data.\n",
    "            train_index (Index): Index of training data.\n",
    "            test_index (Index): Index of testing data.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Train isolation forest on the vectorized training data\n",
    "            self.isolation_forest.fit(vectorized_train)\n",
    "            logger.info(\"Isolation Forest model trained.\")\n",
    "\n",
    "            # Predict anomalies on the testing set\n",
    "            # 1: Indicates that the data point is considered \"normal\" or \"inlier\" by the model.\n",
    "            # -1: Indicates that the data point is considered \"anomalous\" or \"outlier\" by the model.\n",
    "            test_predictions = self.isolation_forest.predict(vectorized_test)\n",
    "            # print(test_predictions)\n",
    "\n",
    "            # Add predictions to the DataFrame\n",
    "            self.df.loc[test_index, 'anomaly'] = test_predictions\n",
    "            # Evaluate the model\n",
    "            true_labels = self.df.loc[test_index, 'anomaly_act'].tolist()\n",
    "\n",
    "            accuracy = accuracy_score(test_predictions, true_labels)  # Assuming anomalies are -1\n",
    "            logger.info(f\"Model accuracy on test data: {accuracy}\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error during isolation forest training: {e}\")\n",
    "\n",
    "    def evaluate_performance(self, test_index):\n",
    "        \"\"\"\n",
    "        Evaluates the performance of the Isolation Forest model on the test data.\n",
    "\n",
    "        Parameters:\n",
    "            test_index (Index): Index of the test data.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Compute the confusion matrix\n",
    "            cm = confusion_matrix(self.df.loc[test_index, 'anomaly_act'], self.df.loc[test_index, 'anomaly'])\n",
    "            logger.info(\"Confusion Matrix:\")\n",
    "            logger.info(cm)\n",
    "\n",
    "            # Print a detailed classification report\n",
    "            report = classification_report(self.df.loc[test_index, 'anomaly_act'], self.df.loc[test_index, 'anomaly'])\n",
    "            logger.info(\"Classification Report:\")\n",
    "            logger.info(report)\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error evaluating performance: {e}\")\n",
    "\n",
    "    def save_isolation_forest_model(self):\n",
    "        \"\"\"\n",
    "        Saves the trained Isolation Forest model and vectorizer to files.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Save the trained vectorizer\n",
    "            joblib.dump(self.vectorizer, self.vectorizer_file)\n",
    "            logger.info(\"Vectorizer saved\")\n",
    "\n",
    "            # Save the trained isolation forest model\n",
    "            joblib.dump(self.isolation_forest, self.trained_model)\n",
    "            logger.info(\"Isolation Forest model saved\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error saving Isolation Forest model: {e}\")\n",
    "\n",
    "    def run(self):\n",
    "        \"\"\"\n",
    "        Orchestrates the entire workflow by calling the methods in sequence.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            self.load_data()\n",
    "            self.preprocess_data()\n",
    "            vectorized_train, vectorized_test, train_index, test_index = self.vectorize_data()\n",
    "            self.train_isolation_forest(vectorized_train, vectorized_test, train_index, test_index)\n",
    "            self.evaluate_performance(test_index)\n",
    "            self.save_isolation_forest_model()\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error in run process: {e}\")\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    input_data_dir = current_directory + '/input/'\n",
    "    processed_result_dir = current_directory + '/output/'\n",
    "    detector = AnomalyClassifier(input_data_dir + 'data_4_modeling.csv', \n",
    "                                 processed_result_dir + 'vectorizer.pkl', \n",
    "                                 processed_result_dir + 'isolation_forest_model.pkl')\n",
    "    detector.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c569d4f6-e46a-4eca-b1c2-8d03b1088394",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
